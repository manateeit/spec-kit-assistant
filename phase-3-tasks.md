# Phase 3: AI-Assisted Task Breakdown

## Overview

The task breakdown phase transforms your technical plan into specific, actionable development tasks. This phase creates a detailed implementation roadmap that follows test-driven development principles, proper dependency management, and GitHub Spec Kit methodology for systematic development execution.

## Learning Objectives

By the end of this phase, you will have:
- Detailed task list with clear acceptance criteria and time estimates
- Proper dependency mapping with parallel execution opportunities identified
- Test-first development sequence ensuring quality from the start
- Task prioritization based on risk, value, and technical dependencies
- Resource allocation and timeline projections
- Comprehensive prompt ready for the `/tasks` command

## Phase Structure

### Stage 1: Work Package Definition (15-20 minutes)
**Objective**: Break implementation plan into logical work packages and task categories

### Stage 2: Task Granularity & Scope (15-20 minutes)
**Objective**: Define individual tasks with appropriate size and clear deliverables

### Stage 3: Dependency Analysis & Sequencing (15-20 minutes)
**Objective**: Map dependencies and identify parallelization opportunities

### Stage 4: Test-Driven Development Integration (10-15 minutes)
**Objective**: Ensure testing requirements are embedded in task structure

### Stage 5: Resource Planning & Estimation (10-15 minutes)
**Objective**: Assign effort estimates and resource requirements

### Stage 6: Comprehensive Task Prompt Generation (10-15 minutes)
**Objective**: Create detailed `/tasks` command prompt

## Detailed Stage Guidance

### Stage 1: Work Package Definition

#### Work Package Analysis Process
```
ðŸ“¦ WORK PACKAGE DEFINITION

Based on your implementation plan, let's organize work into logical packages:

1. Implementation Phase Mapping:
   - What are the major deliverables from your implementation plan?
   - Which deliverables can be worked on independently?
   - What are the natural boundaries for different types of work?

2. Work Package Categories:
   - Infrastructure & Setup: Environment, CI/CD, monitoring, database setup
   - Core Services: Business logic, data access, API endpoints
   - User Interface: Frontend components, user workflows, integration
   - Integration: External APIs, data syncing, event processing
   - Testing & Quality: Test suites, performance testing, security testing
   - Documentation: API docs, deployment guides, user documentation

3. Value-Based Prioritization:
   - Which packages deliver the most user value if completed first?
   - What provides the foundation for other work packages?
   - Where should you validate assumptions early in the process?

4. Risk-Based Sequencing:
   - Which packages have the highest technical uncertainty?
   - What should be built early to reduce project risk?
   - Where are the most critical dependencies?
```

#### Work Package Template
```
WORK PACKAGE STRUCTURE:

Package ID: WP001
Name: [Descriptive package name]
Category: [Infrastructure/Services/UI/Integration/Testing/Documentation]
Priority: [High/Medium/Low]
Value Score: [1-10 based on user/business value]
Risk Score: [1-10 based on technical uncertainty]

Objectives:
- [Primary goal of this work package]
- [Secondary objectives and benefits]
- [Success criteria for package completion]

Deliverables:
âœ“ [Specific, measurable deliverable 1]
âœ“ [Specific, measurable deliverable 2]
âœ“ [Testing requirements for package]

Dependencies:
- Input Dependencies: [What must be complete before starting]
- Output Dependencies: [What packages depend on this completion]

Estimated Effort: [Person-days or story points]
Assigned Resources: [Team member roles or specific individuals]

Example Work Package:

Package ID: WP003
Name: User Authentication System
Category: Core Services
Priority: High
Value Score: 9 (essential for all user features)
Risk Score: 4 (well-understood technology)

Objectives:
- Implement secure user authentication and session management
- Provide role-based authorization framework
- Enable single sign-on integration capability

Deliverables:
âœ“ User registration and login API endpoints
âœ“ JWT token generation and validation service
âœ“ Role-based access control middleware
âœ“ Integration tests for authentication flows
âœ“ Security vulnerability assessment

Dependencies:
- Input Dependencies: Database schema (WP001), API framework (WP002)
- Output Dependencies: All user-facing features depend on authentication

Estimated Effort: 8 person-days
Assigned Resources: Backend developer, Security reviewer
```

#### Quality Checkpoints
- [ ] Work packages have clear boundaries and deliverables
- [ ] Each package can be completed by a small team (2-4 people)
- [ ] Package size allows completion within 1-2 weeks
- [ ] Dependencies between packages are clearly identified
- [ ] Value and risk scores help prioritization decisions

### Stage 2: Task Granularity & Scope

#### Task Definition Process
```
ðŸ“‹ INDIVIDUAL TASK DEFINITION

Let's break each work package into specific, actionable tasks:

1. Task Sizing Guidelines:
   - Each task should be completable by one person in 1-3 days
   - Tasks should have a single, clear deliverable
   - If a task feels too big, what are the logical sub-tasks?

2. Task Definition Criteria:
   - What specific code, configuration, or documentation will be created?
   - What are the acceptance criteria for considering the task complete?
   - How will the completed task be tested and validated?

3. Test-First Task Structure:
   - For each implementation task, what tests need to be written first?
   - How will you validate the task works correctly?
   - What edge cases or error conditions need testing?

4. Task Dependencies:
   - Which tasks within a package must be done sequentially?
   - Which tasks can be worked on in parallel?
   - What external dependencies affect task timing?
```

#### Task Definition Template
```
TASK SPECIFICATION:

Task ID: T001
Work Package: [WP ID and name]
Name: [Clear, action-oriented task name]
Type: [Setup/Implementation/Testing/Documentation]
Priority: [High/Medium/Low]
Parallel Eligible: [Yes/No - can this run parallel to other tasks?]

Description:
[Detailed description of what needs to be accomplished]

Acceptance Criteria:
âœ“ [Specific, testable criteria 1]
âœ“ [Specific, testable criteria 2]
âœ“ [Quality or performance requirement]
âœ“ [Testing requirement]

Implementation Details:
- Files to create/modify: [Specific file paths and purposes]
- Configuration changes: [Settings, environment variables]
- Dependencies to add: [Libraries, packages, services]
- Integration points: [APIs, databases, external services]

Testing Requirements:
- Unit Tests: [What needs unit test coverage]
- Integration Tests: [What integration scenarios to test]
- Manual Testing: [What requires manual validation]
- Performance Tests: [If performance criteria exist]

Time Estimate: [Hours or days]
Complexity: [Low/Medium/High]
Dependencies:
- Blocked by: [Other tasks that must complete first]
- Blocks: [Tasks that depend on this completion]

Definition of Done:
â–¡ Code implementation complete
â–¡ Unit tests written and passing  
â–¡ Integration tests written and passing
â–¡ Code reviewed and approved
â–¡ Documentation updated
â–¡ Feature tested in staging environment

Example Task:

Task ID: T012
Work Package: WP003 - User Authentication System
Name: Implement JWT Token Generation Service
Type: Implementation
Priority: High
Parallel Eligible: No (blocks other auth tasks)

Description:
Create a service that generates and validates JWT tokens for user authentication, including proper token expiration, refresh capability, and secure signing.

Acceptance Criteria:
âœ“ Service generates valid JWT tokens with user ID and role claims
âœ“ Token validation correctly identifies expired and tampered tokens
âœ“ Token refresh mechanism works without requiring re-authentication
âœ“ Service handles concurrent token requests without race conditions
âœ“ All token operations are logged for security auditing

Implementation Details:
- Files to create: services/auth/TokenService.js, middleware/validateToken.js
- Configuration: JWT secret key, token expiration settings
- Dependencies: jsonwebtoken library, crypto library
- Integration points: User database for ID validation

Testing Requirements:
- Unit Tests: Token generation, validation, expiration scenarios
- Integration Tests: Full auth flow with token creation and usage
- Security Tests: Token tampering attempts, timing attacks
- Load Tests: Concurrent token operations

Time Estimate: 2 days
Complexity: Medium
Dependencies:
- Blocked by: T010 (User model implementation), T011 (Database connection service)
- Blocks: T013 (Login endpoint), T014 (Protected route middleware)
```

#### Quality Checkpoints
- [ ] Each task has a single, clear deliverable
- [ ] Acceptance criteria are specific and testable
- [ ] Task size is appropriate (1-3 days for one person)
- [ ] Testing requirements are embedded in task definition
- [ ] Dependencies are clearly identified

### Stage 3: Dependency Analysis & Sequencing

#### Dependency Mapping Process
```
ðŸ”— DEPENDENCY ANALYSIS & SEQUENCING

Let's map task dependencies and identify optimization opportunities:

1. Critical Path Identification:
   - Which sequence of tasks determines the minimum project duration?
   - Where are the bottlenecks that could delay the entire project?
   - What tasks have the most dependencies on them?

2. Parallelization Opportunities:
   - Which tasks can be worked on simultaneously by different people?
   - What tasks are completely independent of each other?
   - Where can team members work in parallel without conflicts?

3. Risk-Based Sequencing:
   - Which high-risk tasks should be done early to validate assumptions?
   - What tasks should be completed early to unblock others?
   - Where should you create proof-of-concepts before full implementation?

4. Resource Optimization:
   - How can you balance workload across team members?
   - Which tasks require specific expertise or skills?
   - Where might resource contention create bottlenecks?
```

#### Dependency Analysis Template
```
DEPENDENCY ANALYSIS:

Critical Path Tasks: [T001 â†’ T005 â†’ T012 â†’ T018 â†’ T025]
Project Duration: [X weeks based on critical path]

Parallelization Matrix:
[Tasks that can run in parallel]

Week 1:
- T001 (Setup) + T002 (Database) + T003 (Documentation) âœ“ PARALLEL
- Cannot parallel: T004 needs T001 completion

Week 2: 
- T005 (Core API) + T006 (Frontend Setup) âœ“ PARALLEL
- Cannot parallel: T007 needs T005 completion

Risk-Based Prioritization:
High Risk, Early Start:
- T008: External API integration (unknown response formats)
- T015: Performance optimization (unproven approach)
- T020: Complex business logic (unclear requirements)

Medium Risk, Standard Timing:
- T010: Database operations (well-understood technology)
- T012: User interface (standard patterns)

Low Risk, Can Be Delayed:
- T025: Documentation updates
- T027: Performance monitoring setup

Resource Allocation:
Backend Developer 1:
- Week 1: T001, T004, T007
- Week 2: T010, T013, T016

Backend Developer 2:
- Week 1: T002, T005, T008
- Week 2: T011, T014, T017

Frontend Developer:
- Week 1: T003, T006
- Week 2: T009, T012, T015

Cross-team Dependencies:
- Frontend needs T007 (API endpoints) by end of Week 1
- Testing needs T010, T011 (core services) by start of Week 3
- Integration needs all services complete by Week 4
```

#### Dependency Visualization
```
TASK DEPENDENCY GRAPH:

[T001: Project Setup]
    â†“
[T002: Database] â†’ [T004: Data Models] â†’ [T007: API Layer]
    â†“                                        â†“
[T003: CI/CD] â†’ [T005: Testing Framework] â†’ [T008: Integration Tests]
                                             â†“
[T006: Frontend Setup] â†’ [T009: UI Components] â†’ [T012: User Workflows]

Parallel Opportunities:
- T001, T002, T003, T006 can all start simultaneously
- T004 and T005 can run in parallel after T002 completes
- T008 and T009 can run in parallel after T007 completes

Bottlenecks:
- T007 (API Layer) blocks multiple frontend tasks
- T004 (Data Models) blocks all backend business logic
- T005 (Testing Framework) blocks all comprehensive testing
```

#### Quality Checkpoints
- [ ] Critical path is identified and optimized
- [ ] Maximum parallel work opportunities are identified
- [ ] High-risk tasks are scheduled early for validation
- [ ] Resource allocation avoids major bottlenecks
- [ ] Dependencies are realistic and necessary

### Stage 4: Test-Driven Development Integration

#### TDD Task Structure Process
```
ðŸ§ª TEST-DRIVEN DEVELOPMENT INTEGRATION

Let's ensure testing is built into the task structure:

1. Test-First Task Ordering:
   - For each implementation task, what tests need to be written first?
   - How will you verify the tests fail before implementation?
   - What's the red-green-refactor cycle for each task?

2. Testing Task Categories:
   - Unit Tests: Individual function and class testing
   - Integration Tests: Component interaction testing
   - Contract Tests: API and service interface testing
   - End-to-End Tests: Complete user workflow testing

3. Quality Gates:
   - What test coverage thresholds must be maintained?
   - When should tests block further development?
   - How will test quality be validated?

4. Test Infrastructure:
   - What testing frameworks and tools are needed?
   - How will test data be managed and refreshed?
   - What test environments are required?
```

#### TDD Task Integration Template
```
TEST-DRIVEN DEVELOPMENT TASK STRUCTURE:

Phase 3.1: Test Infrastructure Setup
T301: Set up unit testing framework
- Configure Jest/Mocha/PyTest for project
- Create test file structure and naming conventions
- Set up code coverage reporting and thresholds
- Establish CI/CD integration for test execution

T302: Create integration testing environment  
- Set up test database with sample data
- Configure API testing tools (Postman/Newman/Supertest)
- Create mock services for external dependencies
- Establish test data refresh and cleanup procedures

Phase 3.2: Contract Tests (Define Interfaces)
T303: Write API contract tests
- Define expected API request/response formats
- Create OpenAPI/Swagger specifications
- Write contract tests for all endpoints
- Verify tests fail (no implementation yet)

T304: Write database contract tests
- Define expected database schema and operations
- Write tests for all data access patterns
- Create tests for data validation and constraints
- Verify tests fail (no implementation yet)

Phase 3.3: Unit Tests (Test Individual Components)  
T305: Write user authentication service tests
- Test token generation with various user inputs
- Test token validation with expired/invalid tokens
- Test edge cases and error conditions
- Verify all tests fail (no implementation yet)

T306: Write user management service tests
- Test user creation with valid/invalid data
- Test user lookup and update operations
- Test authorization and permission checks
- Verify all tests fail (no implementation yet)

Phase 3.4: Implementation (Make Tests Pass)
T307: Implement user authentication service
- Write minimum code to make T305 tests pass
- Follow red-green-refactor cycle
- Ensure all tests pass and maintain coverage
- Refactor for code quality without breaking tests

T308: Implement user management service
- Write minimum code to make T306 tests pass
- Follow red-green-refactor cycle  
- Ensure integration with authentication service
- Refactor for performance and maintainability

Phase 3.5: Integration Tests (Test Component Interactions)
T309: Write authentication flow integration tests
- Test complete login/logout workflows
- Test session management across requests
- Test error scenarios and recovery
- Test performance under concurrent users

T310: Write API integration tests
- Test full request/response cycles
- Test error handling and validation
- Test database transaction consistency
- Test external service integration points
```

#### Test Quality Requirements
```
TESTING QUALITY STANDARDS:

Code Coverage Requirements:
- Unit Tests: Minimum 80% line coverage, 70% branch coverage
- Integration Tests: All API endpoints covered
- Critical Path Coverage: 95% coverage for authentication, payment, data integrity

Test Quality Criteria:
- Tests must be deterministic (no flaky tests)
- Test execution time < 10 minutes for full suite
- Tests must clean up after themselves (no side effects)
- Tests must use realistic data scenarios

Test Maintenance:
- Tests updated with every code change
- Test documentation maintained and current
- Test data refreshed regularly
- Performance of test suite monitored and optimized
```

#### Quality Checkpoints
- [ ] Every implementation task has corresponding test tasks
- [ ] Test tasks are scheduled before implementation tasks
- [ ] Test coverage requirements are clearly defined
- [ ] Test infrastructure setup is planned and scheduled
- [ ] Test quality and maintenance standards are established

### Stage 5: Resource Planning & Estimation

#### Resource Allocation Process
```
ðŸ‘¥ RESOURCE PLANNING & ESTIMATION

Let's plan resource allocation and create realistic estimates:

1. Skill Requirements Analysis:
   - Which tasks require specific technical expertise?
   - Where do you need senior vs. junior developers?
   - What tasks could benefit from pair programming?

2. Capacity Planning:
   - How many hours per week can each team member contribute?
   - Are there competing priorities or other commitments?
   - When are team members available (vacations, other projects)?

3. Estimation Methodology:
   - How will you estimate task complexity and duration?
   - What historical data or benchmarks can guide estimates?
   - How will you account for uncertainty and risk?

4. Timeline Optimization:
   - How can you optimize the schedule for fastest delivery?
   - Where can you add resources to reduce timeline?
   - What's the minimum viable timeline vs. ideal timeline?
```

#### Resource Planning Template
```
RESOURCE ALLOCATION PLAN:

Team Composition:
- Backend Developer (Senior): 40 hours/week, available weeks 1-10
- Backend Developer (Mid-level): 35 hours/week, available weeks 2-12
- Frontend Developer (Senior): 40 hours/week, available weeks 1-8, 10-12
- Frontend Developer (Junior): 30 hours/week, available weeks 1-12
- DevOps Engineer: 20 hours/week, available weeks 1-3, 8-10
- QA Engineer: 25 hours/week, available weeks 4-12

Skill-Based Task Assignment:
High Complexity Tasks (Senior Resources):
- T007: API Architecture Design â†’ Backend Senior
- T015: Performance Optimization â†’ Backend Senior + DevOps
- T020: Security Implementation â†’ Backend Senior + Security Review

Medium Complexity Tasks (Mid-level Resources):
- T010: Database Operations â†’ Backend Mid-level
- T012: User Interface Components â†’ Frontend Senior
- T018: Integration Testing â†’ QA Engineer + Backend Mid-level

Low Complexity Tasks (Junior Resources):
- T003: Documentation â†’ Frontend Junior + Backend Junior
- T025: Configuration Updates â†’ DevOps + Backend Junior
- T027: Monitoring Setup â†’ DevOps + Backend Mid-level

Estimation Matrix:
Task Complexity Factors:
- Technical Complexity: 1-5 (simple CRUD to complex algorithms)
- Integration Complexity: 1-3 (no integration to multiple systems)
- Testing Complexity: 1-3 (basic unit tests to complex scenarios)
- Documentation Needs: 1-2 (minimal to comprehensive)

Example Estimation:
T012: User Authentication Service
- Technical Complexity: 3 (moderate business logic)
- Integration Complexity: 2 (database + external validation)
- Testing Complexity: 3 (security scenarios, edge cases)
- Documentation Needs: 2 (API docs + security notes)
- Base Estimate: 16 hours
- Complexity Multiplier: 1.4 (above average complexity)
- Risk Buffer: 20% (new team member)
- Final Estimate: 23 hours (3 days)

Timeline Scenarios:
Aggressive Timeline (High Risk):
- Total Duration: 8 weeks
- Assumes: No major blockers, optimistic estimates, full team availability
- Risk: 70% chance of delays

Realistic Timeline (Medium Risk):  
- Total Duration: 12 weeks
- Assumes: Some blockers, realistic estimates, normal team availability
- Risk: 30% chance of delays

Conservative Timeline (Low Risk):
- Total Duration: 16 weeks  
- Assumes: Multiple blockers, pessimistic estimates, resource constraints
- Risk: 10% chance of delays
```

#### Quality Checkpoints
- [ ] Resource allocation matches skill requirements
- [ ] Team capacity is realistically assessed
- [ ] Estimates include appropriate buffers for risk and uncertainty
- [ ] Timeline scenarios consider different risk tolerances
- [ ] Resource bottlenecks are identified and mitigated

### Stage 6: Comprehensive Task Prompt Generation

#### Task Prompt Synthesis Process
```
ðŸ“ COMPREHENSIVE TASK PROMPT GENERATION

Based on our task breakdown analysis, I'll create a detailed /tasks prompt that includes:

âœ… Work Package Structure: [Logical groupings with clear deliverables]
âœ… Individual Tasks: [Specific, actionable tasks with acceptance criteria]
âœ… Dependency Mapping: [Sequential and parallel task relationships]
âœ… Test-Driven Structure: [TDD methodology embedded in task flow]
âœ… Resource Allocation: [Skill-based assignments and realistic estimates]
âœ… Quality Gates: [Testing and validation checkpoints]
```

#### Generated Task Prompt Structure
```
/tasks "Break down the implementation plan into actionable tasks with the following structure:

WORK PACKAGE ORGANIZATION:
Organize tasks into logical work packages that align with implementation phases:

Package WP001: Foundation & Infrastructure
- Objectives: [Development environment, CI/CD, monitoring, database setup]
- Duration: [Weeks 1-2]
- Team: [DevOps Engineer + Backend Senior]
- Deliverables: [Operational development environment, automated deployment pipeline]

Package WP002: Core Services & APIs  
- Objectives: [Business logic, data access layer, API endpoints]
- Duration: [Weeks 3-6]
- Team: [Backend Senior + Backend Mid-level]
- Deliverables: [Functional API services with comprehensive testing]

Package WP003: User Interface & Experience
- Objectives: [Frontend components, user workflows, responsive design]
- Duration: [Weeks 4-8]
- Team: [Frontend Senior + Frontend Junior]
- Deliverables: [Complete user interface with accessibility compliance]

Package WP004: Integration & Quality Assurance
- Objectives: [External system integration, performance testing, security validation]
- Duration: [Weeks 7-10]
- Team: [QA Engineer + Full Team for integration testing]
- Deliverables: [Fully integrated system meeting all performance criteria]

TASK SPECIFICATION REQUIREMENTS:
For each task, include the following details:

Task Structure:
- Task ID: [Sequential numbering: T001, T002, etc.]
- Name: [Clear, action-oriented task description]
- Work Package: [Associated work package ID]
- Type: [Setup/Implementation/Testing/Documentation/Integration]
- Priority: [High/Medium/Low based on value and dependencies]
- Parallel Eligible: [Yes/No - can this task run parallel with others?]

Implementation Details:
- Description: [Detailed explanation of work to be completed]
- Acceptance Criteria: [3-5 specific, testable completion conditions]
- Files Affected: [Specific files to create, modify, or configure]
- Dependencies Added: [Libraries, packages, external services required]
- Configuration Changes: [Settings, environment variables, deployment configs]

Testing Requirements (Test-Driven Development):
- Unit Tests: [Specific test scenarios and coverage requirements]
- Integration Tests: [Component interaction and API testing needs]
- Contract Tests: [Interface and service contract validation]
- Performance Tests: [Load, stress, and scalability validation]
- Test Data: [Required test data sets and management approach]

Resource & Timing:
- Estimated Effort: [Hours or story points with confidence level]
- Complexity Rating: [Low/Medium/High with justification]
- Required Skills: [Specific technical expertise or seniority needed]
- Assigned Resources: [Team member roles or specific individuals]
- Dependencies:
  * Blocked By: [Tasks that must complete before this task can start]
  * Blocks: [Tasks that cannot start until this task completes]

Quality Gates:
- Definition of Done: [Specific criteria for task completion]
- Review Requirements: [Code review, architecture review, security review]
- Testing Validation: [What tests must pass for task completion]
- Documentation Updates: [API docs, deployment guides, user documentation]

TEST-DRIVEN DEVELOPMENT SEQUENCE:
Ensure tasks follow proper TDD methodology with this sequence:

Phase 3.1: Test Infrastructure & Setup
T301-T305: Testing framework setup, test data management, CI/CD integration
- Must complete before any implementation tasks
- Includes test environment configuration and tooling setup
- Establishes quality gates and coverage requirements

Phase 3.2: Contract & Interface Tests  
T306-T315: API contracts, service interfaces, database schemas
- Define all external interfaces before implementation
- Create tests that fail initially (no implementation exists)
- Establish clear contracts between system components

Phase 3.3: Unit Test Development
T316-T335: Component-level testing for all business logic
- Write comprehensive unit tests before implementing components
- Cover normal operation, edge cases, and error conditions
- Ensure all tests fail initially (red phase of red-green-refactor)

Phase 3.4: Implementation Tasks
T336-T365: Core component implementation to make tests pass
- Implement minimum code necessary to make tests pass (green phase)
- Follow red-green-refactor cycle for each component
- Maintain test coverage and code quality throughout implementation

Phase 3.5: Integration & End-to-End Testing
T366-T385: System integration and complete workflow testing
- Test component interactions and complete user workflows
- Validate performance, security, and scalability requirements
- Ensure system meets all acceptance criteria

DEPENDENCY MAPPING & PARALLELIZATION:
Specify task dependencies and parallel execution opportunities:

Critical Path Tasks:
[List the sequence of tasks that determines minimum project duration]
- T301 â†’ T306 â†’ T316 â†’ T336 â†’ T366 (Example critical path)
- Total Duration: [X weeks based on critical path analysis]

Parallel Execution Opportunities:
Week 1: [T301, T302, T303] - Can run simultaneously with different team members
Week 2: [T306, T307, T308] - Independent tasks after infrastructure setup
Week 3: [T316, T317, T318] - Unit tests can be developed in parallel
Week 4: [T336, T337, T338] - Implementation tasks with clear boundaries

Dependency Rules:
- All Setup tasks (T301-T305) must complete before any Implementation tasks
- All Contract tests must complete before corresponding Unit tests
- All Unit tests must be written and failing before Implementation begins
- Integration tasks require completion of related Implementation tasks

RESOURCE OPTIMIZATION:
Organize tasks for optimal resource utilization:

Backend Development Track:
- Week 1-2: Senior developer on architecture and critical APIs
- Week 3-4: Mid-level developer on standard CRUD operations
- Week 5-6: Both developers on integration and performance optimization

Frontend Development Track:
- Week 2-3: Senior developer on complex UI components and interactions
- Week 4-5: Junior developer on standard components and styling
- Week 6-7: Both developers on integration and user experience testing

Quality Assurance Track:
- Week 3-4: QA engineer sets up automated testing infrastructure
- Week 5-8: Continuous testing and validation of delivered components
- Week 9-10: Full system testing and performance validation

QUALITY STANDARDS & VALIDATION:
Each task must meet these quality requirements:

Code Quality:
- Unit Test Coverage: Minimum 80% line coverage, 70% branch coverage
- Code Review: All code changes reviewed by senior team member
- Static Analysis: No critical security or quality issues in automated scans
- Documentation: All public interfaces documented with examples

Testing Standards:
- All tests must be deterministic (no flaky tests allowed)
- Test execution time: Full test suite completes in under 10 minutes
- Test isolation: Tests clean up after themselves with no side effects
- Realistic Test Data: Tests use production-like data scenarios

Performance Requirements:
- API Response Times: 95th percentile under 500ms for all endpoints
- Database Query Performance: No queries over 100ms without explicit approval
- Frontend Load Times: Initial page load under 2 seconds on 3G connection
- Concurrent User Support: System handles 100 concurrent users without degradation

RISK MITIGATION IN TASK PLANNING:
Address potential risks through task organization:

Technical Risk Mitigation:
- High-risk tasks scheduled early for validation (T308: External API integration)
- Proof-of-concept tasks for uncertain technologies (T312: Performance optimization POC)
- Alternative implementation paths for critical features (T320: Backup authentication method)

Timeline Risk Mitigation:
- 20% time buffer added to all estimates
- Critical path tasks prioritized and closely monitored
- Parallel work maximized to reduce overall timeline
- Regular milestone reviews to catch delays early

Resource Risk Mitigation:
- Cross-training planned for critical components
- Knowledge sharing sessions scheduled weekly
- Documentation requirements embedded in all tasks
- External consultant identified for specialized needs

SUCCESS CRITERIA & COMPLETION VALIDATION:
Define how task and overall project success will be measured:

Individual Task Success:
- All acceptance criteria met and validated
- All tests passing with required coverage
- Code reviewed and approved by senior team member
- Documentation completed and reviewed

Work Package Success:
- All package deliverables completed and integrated
- Package-level testing completed successfully
- Stakeholder review and approval obtained
- Package deployment to staging environment successful

Overall Project Success:
- All functional requirements from specification implemented
- All performance criteria met in production-like environment
- User acceptance testing completed successfully
- Security and compliance requirements validated
- Knowledge transfer and documentation completed
"
```

## Phase Completion Checklist

Before proceeding to implementation, verify:

### Task Definition Quality
- [ ] Each task has a single, clear deliverable
- [ ] Acceptance criteria are specific and testable
- [ ] Task estimates include appropriate buffers
- [ ] Resource assignments match skill requirements
- [ ] Definition of done is comprehensive and measurable

### Dependency & Sequencing
- [ ] Critical path is identified and optimized
- [ ] Maximum parallel opportunities are planned
- [ ] All task dependencies are necessary and realistic
- [ ] Resource conflicts and bottlenecks are resolved
- [ ] Risk mitigation is embedded in task sequencing

### Test-Driven Development
- [ ] Testing infrastructure setup is planned first
- [ ] All implementation tasks have corresponding test tasks
- [ ] Test tasks are scheduled before implementation tasks
- [ ] Quality gates and coverage requirements are defined
- [ ] Test maintenance and data management are planned

### Resource Planning
- [ ] Team capacity is realistically assessed
- [ ] Skill requirements match available resources
- [ ] Timeline scenarios consider different risk levels
- [ ] Resource optimization maximizes team efficiency
- [ ] Contingency planning addresses resource risks

### Prompt Quality
- [ ] Generated task prompt is comprehensive and actionable
- [ ] All task categories and types are covered
- [ ] Quality standards and validation criteria are clear
- [ ] Resource allocation and timing are realistic
- [ ] Prompt is ready for `/tasks` command execution

## Common Issues and Troubleshooting

### Issue: Tasks Too Large or Vague
**Symptoms**: Tasks that take more than 3 days or have unclear deliverables
**Solution**:
- Break large tasks into smaller, specific subtasks
- Define clear acceptance criteria for each task
- Ensure each task has a single, testable deliverable

### Issue: Dependencies Not Realistic
**Symptoms**: Artificial dependencies or overly complex dependency chains
**Solution**:
- Question whether dependencies are truly necessary
- Look for ways to reduce coupling between tasks
- Create interface contracts to enable parallel development

### Issue: Test Tasks Not Properly Integrated
**Symptoms**: Testing treated as separate activity rather than part of development
**Solution**:
- Embed testing requirements in every implementation task
- Schedule test creation before implementation tasks
- Make test passage a requirement for task completion

### Issue: Resource Allocation Unrealistic
**Symptoms**: Estimates that don't consider team capacity or skill levels
**Solution**:
- Use historical data and team velocity for estimates
- Account for learning curves and skill development needs
- Include realistic buffers for uncertainty and risk

## Next Steps

Once your task breakdown is complete and validated:

1. **Execute Task Generation**: Use your generated prompt with `/tasks` command
2. **Review Generated Tasks**: Validate completeness and feasibility
3. **Refine Task Organization**: Adjust dependencies and sequencing as needed
4. **Begin Implementation**: Start with highest-priority, foundational tasks
5. **Monitor Progress**: Track actual vs. estimated effort for future improvement

The task breakdown becomes your execution roadmap. Ensure it's detailed enough to guide day-to-day development decisions while remaining flexible enough to adapt to discoveries and changes during implementation.